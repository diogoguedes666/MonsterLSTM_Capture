{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Guitar Amp Modelling Training on Google Colab\n",
    "\n",
    "This notebook sets up and runs the neural network training for guitar amplifier/distortion pedal modelling using PyTorch on Google Colab GPUs.\n",
    "\n",
    "## Setup Instructions:\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí **GPU** (T4 or better)\n",
    "2. **Upload Dataset**: Upload your training data as a ZIP file containing the Data folder structure\n",
    "3. **Run All Cells**: Run cells in order from top to bottom\n",
    "4. **Monitor Training**: Use the GPU monitoring cell to track GPU usage during training\n",
    "\n",
    "## Dataset Structure:\n",
    "Your ZIP file should contain:\n",
    "```\n",
    "Data/\n",
    "  ‚îú‚îÄ‚îÄ train/\n",
    "  ‚îÇ   ‚îú‚îÄ‚îÄ dls2-input.wav\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ dls2-target.wav\n",
    "  ‚îú‚îÄ‚îÄ val/\n",
    "  ‚îÇ   ‚îú‚îÄ‚îÄ dls2-input.wav\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ dls2-target.wav\n",
    "  ‚îî‚îÄ‚îÄ test/\n",
    "      ‚îú‚îÄ‚îÄ dls2-input.wav\n",
    "      ‚îî‚îÄ‚îÄ dls2-target.wav\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and setup\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU Setup Check\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"Current GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"Current GPU Memory Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\\n‚úÖ Using device: {device}\")\n",
    "    \n",
    "    # Clear any existing GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úÖ GPU cache cleared\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No GPU detected!\")\n",
    "    print(\"   Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")\n",
    "    print(\"   Training will be VERY slow on CPU!\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies for GPU training\n",
    "print(\"Installing PyTorch with CUDA support...\")\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -q\n",
    "\n",
    "print(\"\\nInstalling audio processing libraries...\")\n",
    "%pip install numpy scipy matplotlib pyyaml tqdm librosa tensorboard -q\n",
    "\n",
    "print(\"\\nInstalling additional utilities...\")\n",
    "%pip install psutil -q\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")\n",
    "print(\"\\nVerifying CUDA installation...\")\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA {torch.version.cuda} is working!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  CUDA not available - check GPU runtime settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone or upload the repository\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Repository Setup\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if we're already in the repo directory\n",
    "if os.path.exists('CoreAudioML') and os.path.exists('dist_model_recnet.py'):\n",
    "    print(\"‚úÖ Repository files already present in current directory\")\n",
    "    repo_path = os.getcwd()\n",
    "    print(f\"   Working directory: {repo_path}\")\n",
    "else:\n",
    "    # Try to clone the repository - use the correct repository name\n",
    "    repo_name = 'MonsterLSTM_Capture'\n",
    "    \n",
    "    # Clean up any old clones\n",
    "    if os.path.exists(repo_name):\n",
    "        print(f\"Removing old {repo_name} directory...\")\n",
    "        shutil.rmtree(repo_name, ignore_errors=True)\n",
    "    \n",
    "    # Also check for old Automated-GuitarAmpModelling-3 directory\n",
    "    if os.path.exists('Automated-GuitarAmpModelling-3'):\n",
    "        print(\"Removing old Automated-GuitarAmpModelling-3 directory...\")\n",
    "        shutil.rmtree('Automated-GuitarAmpModelling-3', ignore_errors=True)\n",
    "    \n",
    "    # Clone the repository from the correct GitHub URL\n",
    "    print(f\"Cloning repository from GitHub...\")\n",
    "    !git clone https://github.com/diogoguedes666/MonsterLSTM_Capture.git\n",
    "    \n",
    "    if os.path.exists(repo_name):\n",
    "        # Change to the repository directory\n",
    "        # Note: os.chdir() persists across cells in Colab\n",
    "        os.chdir(repo_name)\n",
    "        repo_path = os.getcwd()\n",
    "        print(f\"‚úÖ Repository cloned successfully\")\n",
    "        print(f\"   Working directory: {repo_path}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Repository clone failed!\")\n",
    "        print(\"   Please check your internet connection or upload files manually\")\n",
    "        repo_path = os.getcwd()\n",
    "\n",
    "# Verify we're in the right directory\n",
    "print(f\"\\nüìã Verification:\")\n",
    "print(f\"   Current directory: {os.getcwd()}\")\n",
    "print(f\"   CoreAudioML exists: {os.path.exists('CoreAudioML')}\")\n",
    "print(f\"   dist_model_recnet.py exists: {os.path.exists('dist_model_recnet.py')}\")\n",
    "\n",
    "if os.path.exists('CoreAudioML'):\n",
    "    print(f\"\\n‚úÖ CoreAudioML module found!\")\n",
    "    core_files = os.listdir('CoreAudioML')\n",
    "    print(f\"   Module files: {', '.join(core_files[:5])}\")\n",
    "    if len(core_files) > 5:\n",
    "        print(f\"   ... and {len(core_files) - 5} more files\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  CoreAudioML not found!\")\n",
    "    print(f\"   Current directory contents:\")\n",
    "    for item in os.listdir('.')[:10]:\n",
    "        print(f\"      - {item}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "import os\n",
    "\n",
    "dirs_to_create = [\n",
    "    'Data/train',\n",
    "    'Data/val', \n",
    "    'Data/test',\n",
    "    'Results',\n",
    "    'Configs'\n",
    "]\n",
    "\n",
    "for dir_path in dirs_to_create:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"‚úÖ Created: {dir_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ All directories created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Generate test signals if you don't have real training data\n",
    "# This creates synthetic audio data for testing the training pipeline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "import os\n",
    "\n",
    "def generate_test_audio(filename, duration=10, sample_rate=44100, freq=440):\n",
    "    \"\"\"Generate a simple test audio file\"\"\"\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    # Create a mix of sine waves for more interesting content\n",
    "    audio = 0.3 * np.sin(freq * 2 * np.pi * t)  # 440 Hz sine wave\n",
    "    audio += 0.2 * np.sin(2 * freq * 2 * np.pi * t)  # 880 Hz harmonic\n",
    "    audio += 0.1 * np.sin(3 * freq * 2 * np.pi * t)  # 1320 Hz harmonic\n",
    "\n",
    "    # Normalize to prevent clipping\n",
    "    audio = audio / np.max(np.abs(audio)) * 0.8\n",
    "\n",
    "    # Convert to 16-bit PCM\n",
    "    audio_int16 = (audio * 32767).astype(np.int16)\n",
    "\n",
    "    wavfile.write(filename, sample_rate, audio_int16)\n",
    "    print(f\"Generated test audio: {filename}\")\n",
    "\n",
    "# Generate test data\n",
    "generate_test_audio(\"Data/train/dls2-input.wav\", duration=30)\n",
    "generate_test_audio(\"Data/train/dls2-target.wav\", duration=30)  # This would be your \"amp output\"\n",
    "\n",
    "generate_test_audio(\"Data/val/dls2-input.wav\", duration=10)\n",
    "generate_test_audio(\"Data/val/dls2-target.wav\", duration=10)\n",
    "\n",
    "generate_test_audio(\"Data/test/dls2-input.wav\", duration=5)\n",
    "generate_test_audio(\"Data/test/dls2-target.wav\", duration=5)\n",
    "\n",
    "print(\"Test data generation complete!\")\n",
    "print(\"Note: For real amp modelling, replace these with actual guitar -> amp recordings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your training dataset as a ZIP file\n",
    "from google.colab import files\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Dataset Upload\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüì¶ Please upload your ZIP file containing the Data folder\")\n",
    "print(\"\\nYour ZIP file should have this structure:\")\n",
    "print(\"  Data.zip\")\n",
    "print(\"    ‚îî‚îÄ‚îÄ Data/\")\n",
    "print(\"        ‚îú‚îÄ‚îÄ train/\")\n",
    "print(\"        ‚îÇ   ‚îú‚îÄ‚îÄ dls2-input.wav\")\n",
    "print(\"        ‚îÇ   ‚îî‚îÄ‚îÄ dls2-target.wav\")\n",
    "print(\"        ‚îú‚îÄ‚îÄ val/\")\n",
    "print(\"        ‚îÇ   ‚îú‚îÄ‚îÄ dls2-input.wav\")\n",
    "print(\"        ‚îÇ   ‚îî‚îÄ‚îÄ dls2-target.wav\")\n",
    "print(\"        ‚îî‚îÄ‚îÄ test/\")\n",
    "print(\"            ‚îú‚îÄ‚îÄ dls2-input.wav\")\n",
    "print(\"            ‚îî‚îÄ‚îÄ dls2-target.wav\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Upload ZIP file\n",
    "print(\"\\nüì§ Click 'Choose Files' to upload your dataset ZIP file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Find the ZIP file\n",
    "zip_filename = None\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        zip_filename = filename\n",
    "        print(f\"\\n‚úÖ Found ZIP file: {zip_filename}\")\n",
    "        break\n",
    "\n",
    "if not zip_filename:\n",
    "    print(\"‚ùå No ZIP file found in upload!\")\n",
    "    print(\"   Please make sure you uploaded a .zip file\")\n",
    "else:\n",
    "    # Extract ZIP file\n",
    "    print(f\"\\nüìÇ Extracting {zip_filename}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(\"‚úÖ Extraction complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting ZIP: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Check if Data folder exists (handle different ZIP structures)\n",
    "    data_path = None\n",
    "    if os.path.exists('Data'):\n",
    "        data_path = 'Data'\n",
    "    elif os.path.exists(os.path.join(zip_filename.replace('.zip', ''), 'Data')):\n",
    "        # ZIP might have extracted to a subfolder\n",
    "        data_path = os.path.join(zip_filename.replace('.zip', ''), 'Data')\n",
    "        # Move Data folder to root\n",
    "        shutil.move(data_path, 'Data')\n",
    "        data_path = 'Data'\n",
    "    \n",
    "    if data_path and os.path.exists(data_path):\n",
    "        print(f\"\\n‚úÖ Data folder found at: {data_path}\")\n",
    "        \n",
    "        # Verify required files\n",
    "        required_files = [\n",
    "            'Data/train/dls2-input.wav',\n",
    "            'Data/train/dls2-target.wav',\n",
    "            'Data/val/dls2-input.wav',\n",
    "            'Data/val/dls2-target.wav',\n",
    "            'Data/test/dls2-input.wav',\n",
    "            'Data/test/dls2-target.wav'\n",
    "        ]\n",
    "        \n",
    "        missing = []\n",
    "        found = []\n",
    "        for filepath in required_files:\n",
    "            if os.path.exists(filepath):\n",
    "                found.append(filepath)\n",
    "            else:\n",
    "                missing.append(filepath)\n",
    "        \n",
    "        print(f\"\\nüìä File verification:\")\n",
    "        print(f\"   ‚úÖ Found: {len(found)}/{len(required_files)} files\")\n",
    "        \n",
    "        if missing:\n",
    "            print(f\"\\n‚ö†Ô∏è  Missing files:\")\n",
    "            for f in missing:\n",
    "                print(f\"   - {f}\")\n",
    "            print(\"\\n‚ö†Ô∏è  Training may fail without all required files!\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ All required files found!\")\n",
    "        \n",
    "        # Show data structure\n",
    "        print(\"\\nüìÅ Data structure:\")\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_path = f'Data/{split}'\n",
    "            if os.path.exists(split_path):\n",
    "                files_in_split = os.listdir(split_path)\n",
    "                print(f\"   {split_path}/: {len(files_in_split)} file(s)\")\n",
    "                for f in files_in_split[:3]:  # Show first 3 files\n",
    "                    print(f\"      - {f}\")\n",
    "                if len(files_in_split) > 3:\n",
    "                    print(f\"      ... and {len(files_in_split) - 3} more\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Data folder not found in ZIP!\")\n",
    "        print(f\"   Extracted contents: {os.listdir('.')[:10]}\")\n",
    "        print(\"\\n   Please check your ZIP file structure.\")\n",
    "    \n",
    "    # Clean up zip file\n",
    "    if os.path.exists(zip_filename):\n",
    "        os.remove(zip_filename)\n",
    "        print(f\"\\nüóëÔ∏è  Cleaned up: {zip_filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Dataset upload complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RNN3.json config file optimized for GPU training\n",
    "import json\n",
    "\n",
    "config = {\n",
    "    \"model\": \"SimpleRNN\",\n",
    "    \"input_size\": 1,\n",
    "    \"output_size\": 1,\n",
    "    \"num_blocks\": 2,\n",
    "    \"hidden_size\": 96,  # Optimized for GPU (can handle larger models)\n",
    "    \"unit_type\": \"LSTM\",\n",
    "    \"skip_con\": True,\n",
    "    \"segment_length\": 22050,\n",
    "    \"batch_size\": 512,  # GPU-friendly batch size (adjust if OOM)\n",
    "    \"epochs\": 100,\n",
    "    \"learn_rate\": 0.005,\n",
    "    \"validation_f\": 5,\n",
    "    \"validation_p\": 20,\n",
    "    \"loss_fcns\": {\n",
    "        \"ESR\": 0.75,\n",
    "        \"DC\": 0.10,\n",
    "        \"HFHinge\": 0.15\n",
    "    },\n",
    "    \"pre_filt\": \"None\",\n",
    "    \"cuda\": 1,  # Enable CUDA/GPU\n",
    "    \"weight_decay\": 0.000001,\n",
    "    \"gradient_clip\": 1.0,\n",
    "    \"hf_hinge_fmin\": 10000,\n",
    "    \"hf_hinge_strength\": 0.5\n",
    "}\n",
    "\n",
    "# Save config file\n",
    "config_path = 'Configs/RNN3.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Config file created: {config_path}\")\n",
    "print(f\"\\nüìã Configuration:\")\n",
    "print(f\"   Model: {config['model']}\")\n",
    "print(f\"   Hidden Size: {config['hidden_size']}\")\n",
    "print(f\"   Batch Size: {config['batch_size']}\")\n",
    "print(f\"   Epochs: {config['epochs']}\")\n",
    "print(f\"   Learning Rate: {config['learn_rate']}\")\n",
    "print(f\"   GPU Enabled: {config['cuda'] == 1}\")\n",
    "print(f\"\\nüí° Tip: If you get CUDA out of memory errors, reduce batch_size to 256 or 128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data files exist\n",
    "!ls -la Data/train/\n",
    "!ls -la Data/val/\n",
    "!ls -la Data/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports and setup\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Module Import Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ensure we're in the correct directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "\n",
    "# Check multiple possible locations for the repository\n",
    "possible_paths = [\n",
    "    current_dir,  # Current directory\n",
    "    'MonsterLSTM_Capture',  # If we're in /content\n",
    "    'Automated-GuitarAmpModelling-3',  # Old name (if exists)\n",
    "    os.path.join('..', 'MonsterLSTM_Capture'),  # Parent directory\n",
    "]\n",
    "\n",
    "repo_path = None\n",
    "for path in possible_paths:\n",
    "    full_path = os.path.abspath(path) if not os.path.isabs(path) else path\n",
    "    if os.path.exists(os.path.join(full_path, 'CoreAudioML')) and os.path.exists(os.path.join(full_path, 'dist_model_recnet.py')):\n",
    "        repo_path = full_path\n",
    "        print(f\"‚úÖ Found repository at: {repo_path}\")\n",
    "        if full_path != current_dir:\n",
    "            os.chdir(full_path)\n",
    "            print(f\"   Changed to: {os.getcwd()}\")\n",
    "        break\n",
    "\n",
    "if repo_path is None:\n",
    "    print(\"‚ö†Ô∏è  Repository not found in expected locations!\")\n",
    "    print(f\"   Current directory: {current_dir}\")\n",
    "    print(f\"   Contents: {os.listdir('.')[:10]}\")\n",
    "    # Try to find it by walking\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        if 'CoreAudioML' in dirs and 'dist_model_recnet.py' in files:\n",
    "            repo_path = root\n",
    "            os.chdir(root)\n",
    "            print(f\"‚úÖ Found repository at: {os.path.abspath(root)}\")\n",
    "            break\n",
    "\n",
    "# Add current directory to Python path\n",
    "current_dir = os.getcwd()\n",
    "sys.path.insert(0, current_dir)\n",
    "print(f\"\\n‚úÖ Added to Python path: {current_dir}\")\n",
    "\n",
    "# Verify required files exist\n",
    "required_files = [\n",
    "    'CoreAudioML',\n",
    "    'dist_model_recnet.py',\n",
    "    'Configs/RNN3.json',\n",
    "    'Data/train',\n",
    "    'Data/val',\n",
    "    'Data/test'\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Checking required files:\")\n",
    "for item in required_files:\n",
    "    exists = os.path.exists(item)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {item}\")\n",
    "\n",
    "# Test imports\n",
    "print(\"\\nüîç Testing module imports...\")\n",
    "try:\n",
    "    import CoreAudioML.miscfuncs as miscfuncs\n",
    "    print(\"   ‚úÖ CoreAudioML.miscfuncs\")\n",
    "    \n",
    "    import CoreAudioML.training as training\n",
    "    print(\"   ‚úÖ CoreAudioML.training\")\n",
    "    \n",
    "    import CoreAudioML.dataset as dataset\n",
    "    print(\"   ‚úÖ CoreAudioML.dataset\")\n",
    "    \n",
    "    import CoreAudioML.networks as networks\n",
    "    print(\"   ‚úÖ CoreAudioML.networks\")\n",
    "    \n",
    "    print(\"\\n‚úÖ All CoreAudioML modules imported successfully!\")\n",
    "    \n",
    "    # Verify GPU availability\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\n‚úÖ GPU ready: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  GPU not available - training will be slow!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Import error: {e}\")\n",
    "    print(f\"   Current directory: {os.getcwd()}\")\n",
    "    if os.path.exists('CoreAudioML'):\n",
    "        print(f\"   CoreAudioML contents: {os.listdir('CoreAudioML')}\")\n",
    "    else:\n",
    "        print(\"   CoreAudioML directory not found!\")\n",
    "        print(f\"   Current directory contents:\")\n",
    "        for item in os.listdir('.')[:15]:\n",
    "            item_path = os.path.join('.', item)\n",
    "            item_type = \"DIR\" if os.path.isdir(item_path) else \"FILE\"\n",
    "            print(f\"      [{item_type}] {item}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start GPU Training!\n",
    "# This cell runs the actual training on GPU\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Starting GPU Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Clear GPU cache before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"‚úÖ GPU cache cleared\")\n",
    "    print(f\"   Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - training will be slow on CPU!\")\n",
    "\n",
    "# Set environment variable to ensure GPU is used\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(\"   This may take a while. Monitor progress below.\")\n",
    "print(\"   You can check GPU usage in the monitoring cell (Cell 13)\")\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Run training with GPU support\n",
    "# The script will automatically detect and use GPU if available\n",
    "!python dist_model_recnet.py --load_config RNN3 --epochs 100 --device dls2 --cuda 1\n",
    "\n",
    "# Clean up after training\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"\\n‚úÖ Training complete! GPU memory cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Continue training or run with custom parameters\n",
    "# Uncomment and modify as needed\n",
    "\n",
    "# Example 1: Run more epochs\n",
    "# !python dist_model_recnet.py --load_config RNN3 --epochs 200 --device dls2 --cuda 1\n",
    "\n",
    "# Example 2: Adjust batch size (if you get CUDA OOM errors, reduce this)\n",
    "# !python dist_model_recnet.py --load_config RNN3 --epochs 100 --batch_size 256 --device dls2 --cuda 1\n",
    "\n",
    "# Example 3: Train with larger model\n",
    "# !python dist_model_recnet.py --load_config RNN3 --epochs 100 --hidden_size 128 --device dls2 --cuda 1\n",
    "\n",
    "print(\"üí° Tips:\")\n",
    "print(\"   - If you get 'CUDA out of memory', reduce batch_size to 256 or 128\")\n",
    "print(\"   - Larger hidden_size (128, 256) gives better quality but uses more GPU memory\")\n",
    "print(\"   - Monitor GPU usage in Cell 13 while training\")\n",
    "print(\"   - Training checkpoints are saved every 10 epochs in Results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "!ls -la Results/\n",
    "\n",
    "# If training completed, you should see directories like 'dls2-RNN3' with model files\n",
    "# You can download the results:\n",
    "# from google.colab import files\n",
    "# !zip -r results.zip Results/\n",
    "# files.download('results.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GPU usage during training\n",
    "# Run this cell in a separate tab while training is running to monitor GPU utilization\n",
    "\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU Monitoring\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nPress Ctrl+C to stop monitoring\\n\")\n",
    "\n",
    "try:\n",
    "    # Monitor GPU every 5 seconds\n",
    "    for i in range(12):  # Monitor for 1 minute (12 * 5 seconds)\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=timestamp,name,utilization.gpu,utilization.memory,memory.used,memory.free,temperature.gpu', \n",
    "             '--format=csv,noheader,nounits'],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"\\n[{time.strftime('%H:%M:%S')}] GPU Status:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Could not query GPU. Make sure GPU runtime is enabled.\")\n",
    "            break\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n‚úÖ Monitoring stopped\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Better Training:\n",
    "\n",
    "1. **GPU Memory**: If you get CUDA out of memory errors, reduce `batch_size` in the config\n",
    "2. **Training Time**: Start with fewer epochs (50-100) to test, then increase\n",
    "3. **Model Size**: Larger `hidden_size` (64, 128) gives better quality but slower training\n",
    "4. **Data Quality**: Real guitar recordings give much better results than synthetic data\n",
    "5. **Monitoring**: Use TensorBoard to monitor training progress\n",
    "\n",
    "## Troubleshooting:\n",
    "\n",
    "- **Import errors**: Make sure all files are uploaded/cloned correctly\n",
    "- **CUDA errors**: Ensure GPU runtime is enabled\n",
    "- **Memory errors**: Reduce batch size or use gradient accumulation\n",
    "- **Data errors**: Check that WAV files are mono, 44.1kHz, and properly matched\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. Download trained models from the Results folder\n",
    "2. Test inference with `proc_audio.py` on new audio\n",
    "3. Experiment with different configurations (RNN1.json, RNN2.json)\n",
    "4. Try different architectures or hyperparameters"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
