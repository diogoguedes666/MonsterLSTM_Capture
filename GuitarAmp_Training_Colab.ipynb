{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Guitar Amp Modelling Training on Google Colab\n",
    "\n",
    "This notebook sets up and runs the neural network training for guitar amplifier/distortion pedal modelling using PyTorch.\n",
    "\n",
    "## Setup Instructions:\n",
    "1. Make sure you have GPU runtime enabled: Runtime → Change runtime type → Hardware accelerator → GPU\n",
    "2. Upload your training data files to Colab (or use the provided generate_test_signals.py)\n",
    "3. Run the cells in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. This training will be very slow on CPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install numpy scipy matplotlib pyyaml tqdm librosa tensorboard\n",
    "!pip install pytest black mypy  # Optional development tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/diogoguedes666/Automated-GuitarAmpModelling-3.git\n",
    "%cd Automated-GuitarAmpModelling-3\n",
    "\n",
    "# Alternative: If you want to upload your local files instead of cloning\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()  # Upload your project files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "!mkdir -p Data/train Data/val Data/test Results\n",
    "!mkdir -p Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Generate test signals if you don't have real training data\n",
    "# This creates synthetic audio data for testing the training pipeline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "import os\n",
    "\n",
    "def generate_test_audio(filename, duration=10, sample_rate=44100, freq=440):\n",
    "    \"\"\"Generate a simple test audio file\"\"\"\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    # Create a mix of sine waves for more interesting content\n",
    "    audio = 0.3 * np.sin(freq * 2 * np.pi * t)  # 440 Hz sine wave\n",
    "    audio += 0.2 * np.sin(2 * freq * 2 * np.pi * t)  # 880 Hz harmonic\n",
    "    audio += 0.1 * np.sin(3 * freq * 2 * np.pi * t)  # 1320 Hz harmonic\n",
    "\n",
    "    # Normalize to prevent clipping\n",
    "    audio = audio / np.max(np.abs(audio)) * 0.8\n",
    "\n",
    "    # Convert to 16-bit PCM\n",
    "    audio_int16 = (audio * 32767).astype(np.int16)\n",
    "\n",
    "    wavfile.write(filename, sample_rate, audio_int16)\n",
    "    print(f\"Generated test audio: {filename}\")\n",
    "\n",
    "# Generate test data\n",
    "generate_test_audio(\"Data/train/dls2-input.wav\", duration=30)\n",
    "generate_test_audio(\"Data/train/dls2-target.wav\", duration=30)  # This would be your \"amp output\"\n",
    "\n",
    "generate_test_audio(\"Data/val/dls2-input.wav\", duration=10)\n",
    "generate_test_audio(\"Data/val/dls2-target.wav\", duration=10)\n",
    "\n",
    "generate_test_audio(\"Data/test/dls2-input.wav\", duration=5)\n",
    "generate_test_audio(\"Data/test/dls2-target.wav\", duration=5)\n",
    "\n",
    "print(\"Test data generation complete!\")\n",
    "print(\"Note: For real amp modelling, replace these with actual guitar -> amp recordings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Upload your own training data\n",
    "# Uncomment the lines below if you want to upload your own WAV files\n",
    "\n",
    "# from google.colab import files\n",
    "# print(\"Upload your training input WAV file (guitar signal)\")\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     os.rename(filename, f\"Data/train/dls2-input.wav\")\n",
    "\n",
    "# print(\"Upload your training target WAV file (amp output)\")\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     os.rename(filename, f\"Data/train/dls2-target.wav\")\n",
    "\n",
    "# print(\"Upload validation input WAV file\")\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     os.rename(filename, f\"Data/val/dls2-input.wav\")\n",
    "\n",
    "# print(\"Upload validation target WAV file\")\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     os.rename(filename, f\"Data/val/dls2-target.wav\")\n",
    "\n",
    "# print(\"Upload test input WAV file\")\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     os.rename(filename, f\"Data/test/dls2-input.wav\")\n",
    "\n",
    "# print(\"Upload test target WAV file\")\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     os.rename(filename, f\"Data/test/dls2-target.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RNN3.json config file\n",
    "config_content = '''{\n",
    "  \"model\": \"SimpleRNN\",\n",
    "  \"input_size\": 1,\n",
    "  \"output_size\": 1,\n",
    "  \"num_blocks\": 2,\n",
    "  \"hidden_size\": 32,\n",
    "  \"unit_type\": \"LSTM\",\n",
    "  \"skip_con\": true,\n",
    "  \"segment_length\": 22050,\n",
    "  \"batch_size\": 512,\n",
    "  \"epochs\": 100,\n",
    "  \"learn_rate\": 0.005,\n",
    "  \"validation_f\": 5,\n",
    "  \"validation_p\": 20,\n",
    "  \"loss_fcns\": {\"ESRPre\": 0.9, \"DC\": 0.1},\n",
    "  \"pre_filt\": \"high_pass\",\n",
    "  \"cuda\": 1,\n",
    "  \"weight_decay\": 0.000001,\n",
    "  \"gradient_clip\": 1.0\n",
    "}\n",
    "'''\n",
    "\n",
    "with open('Configs/RNN3.json', 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"Config file created: Configs/RNN3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data files exist\n",
    "!ls -la Data/train/\n",
    "!ls -la Data/val/\n",
    "!ls -la Data/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a quick test to make sure the CoreAudioML modules can be imported\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "try:\n",
    "    import CoreAudioML.miscfuncs as miscfuncs\n",
    "    import CoreAudioML.training as training\n",
    "    import CoreAudioML.dataset as dataset\n",
    "    import CoreAudioML.networks as networks\n",
    "    print(\"✓ All CoreAudioML modules imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Import error: {e}\")\n",
    "    print(\"Check that all files are in the correct locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training!\n",
    "# This will run the main training script with the RNN3 configuration\n",
    "\n",
    "# First, let's do a quick dry run to make sure everything works\n",
    "print(\"Testing training setup with 1 epoch...\")\n",
    "!python dist_model_recnet.py --load_config RNN3 --epochs 1 --batch_size 64 --device dls2\n",
    "\n",
    "# If the test works, you can run the full training:\n",
    "# !python dist_model_recnet.py --load_config RNN3 --epochs 100 --device dls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to run the full training (this will take time), uncomment and run:\n",
    "# !python dist_model_recnet.py --load_config RNN3 --epochs 200 --device dls2\n",
    "\n",
    "# Or run with different parameters:\n",
    "# !python dist_model_recnet.py --load_config RNN3 --epochs 100 --batch_size 1024 --hidden_size 64 --device dls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "!ls -la Results/\n",
    "\n",
    "# If training completed, you should see directories like 'dls2-RNN3' with model files\n",
    "# You can download the results:\n",
    "# from google.colab import files\n",
    "# !zip -r results.zip Results/\n",
    "# files.download('results.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GPU usage during training (run this in a separate cell while training)\n",
    "# !nvidia-smi --query-gpu=timestamp,name,utilization.gpu,utilization.memory,memory.used,memory.free --format=csv -l 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Better Training:\n",
    "\n",
    "1. **GPU Memory**: If you get CUDA out of memory errors, reduce `batch_size` in the config\n",
    "2. **Training Time**: Start with fewer epochs (50-100) to test, then increase\n",
    "3. **Model Size**: Larger `hidden_size` (64, 128) gives better quality but slower training\n",
    "4. **Data Quality**: Real guitar recordings give much better results than synthetic data\n",
    "5. **Monitoring**: Use TensorBoard to monitor training progress\n",
    "\n",
    "## Troubleshooting:\n",
    "\n",
    "- **Import errors**: Make sure all files are uploaded/cloned correctly\n",
    "- **CUDA errors**: Ensure GPU runtime is enabled\n",
    "- **Memory errors**: Reduce batch size or use gradient accumulation\n",
    "- **Data errors**: Check that WAV files are mono, 44.1kHz, and properly matched\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. Download trained models from the Results folder\n",
    "2. Test inference with `proc_audio.py` on new audio\n",
    "3. Experiment with different configurations (RNN1.json, RNN2.json)\n",
    "4. Try different architectures or hyperparameters"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
